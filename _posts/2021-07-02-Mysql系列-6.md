---
layout:     post
title:      Mysql系列-6
subtitle:   Mysql详解
date:       2021-07-02
author:     CodingAndLiving
header-img: img/com01.jpg
catalog: true
tags:
    - Mysql
    - 原理
    - 底层
---
# 前言

> 在繁杂的世界，能够沉下心来，梳理下知识体系，其实是一件很放松的诗意。


# MVCC多版本并发控制机制 

Mysql在可重复读隔离级别下如何保证事务较高的隔离性，同样的sql查询语句在一个事务 里多次执行查询结果相同，就算其它事务对数据有修改也不会影响当前事务sql语句的查询结果。 这个隔离性就是靠MVCC(Multi-Version Concurrency Control)机制来保证的，对一行数据的读和写两个操作默认 是不会通过加锁互斥来保证隔离性，避免了频繁加锁互斥，而在串行化隔离级别为了保证较高的隔离性是通过将所有操 作加锁互斥来实现的。

Mysql在读已提交和可重复读隔离级别下都实现了MVCC机制。

# undo日志版本链与read view机制详解 

undo日志版本链是指一行数据被多个事务依次修改过后，在每个事务修改完后，Mysql会保留修改前的数据undo回滚 日志，并且用两个隐藏字段trx_id和roll_pointer把这些undo日志串联起来形成一个历史记录版本链

可以如下理解：

1. 每一行数据，其实额外含有两个隐藏字段，分别是trx_id和roll_pointer；
2. trx_id 标识事务id，是指该行数据对应的事务id；
3. roll_pointer 一个指针，指向该行记录的上一个版本记录。
4. 每一个版本记录，都会对应一个事务id。

在可重复读隔离级别，当事务开启，执行任何查询sql时会生成当前事务的一致性视图read-view，**该视图在事务结束 之前都不会变化**(如果是**读已提交隔离级别在每次执行查询sql时都会重新生成**)，

> 这点差异就是读已提交和可重复读隔离级别， 一个能解决不可重复读问题，一个不能的差异了。


这个视图由执行查询时所有未提交事 务id数组（数组里最小的id为min_id）和已创建的最大事务id（max_id）组成，事务里的任何sql查询结果需要从对应 版本链里的最新数据开始逐条跟read-view做比对从而得到最终的快照结果。

> 查询视图 = 未提交的事务id数组  + 数组内最小的事务id（min_id）  + 当前已经创建的最大的事务id（max_id）。


版本链比对规则： 
1. 如果 row 的 trx_id 落在绿色部分( trx_id < min_id )，表示这个版本是已提交的事务生成的，这个数据是可见的； 
2. 如果 row 的 trx_id 落在红色部分( trx_id>max_id )，表示这个版本是由将来启动的事务生成的，是不可见的(若 row 的 trx_id 就是当前自己的事务是可见的）；
3. 如果 row 的 trx_id 落在黄色部分(min_id <=trx_id<= max_id)，那就包括两种情况 
	1. 若 row 的 trx_id 在视图数组中，表示这个版本是由还没提交的事务生成的，不可见(若 row 的 trx_id 就是当前自 己的事务是可见的)； 
	2. 若 row 的 trx_id 不在视图数组中，表示这个版本是已经提交了的事务生成的，可见。


对于**删除**的情况可以认为是update的特殊情况，会将版本链上最新的数据复制一份，然后将trx_id修改成删除操作的 trx_id，同时在该条记录的头信息（record header）里的（deleted_flag）标记位写上true，来表示当前记录已经被 删除，在查询时按照上面的规则查到对应的记录如果delete_flag标记位为true，意味着记录已被删除，则不返回数 据。

**注意**：begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个修改操作InnoDB表的语句， 事务才真正启动，才会向mysql申请事务id，mysql内部是严格按照事务的启动顺序来分配事务id的。

# 总结： 
MVCC机制的实现就是通过read-view机制与undo版本链比对机制，使得不同的事务会根据数据版本链对比规则读取 同一条数据在版本链上的不同版本数据。

# Innodb引擎SQL执行的BufferPool缓存机制

以update语句为例，

> update tableName set name='hello' where id=8;

1. 在执行器调用执行引擎后面，会发生如下故事。
2. 先从磁盘文件，加载数据到buffer pool缓存池。
3. 往undo日志文件里面编写更新数据的旧值，当事务提交失败时候，用于回滚数据
4. 更新内存数据，即buffer pool的值。
5. 写入redo日志
6. 准备提交事务，先将redo日志写入磁盘，就是新值；如果事务提交成功后，buffer pool的数据没来得及写磁盘，没了，可以拿redo日志恢复buffer pool。
7. 准备提交事务，先将binlog写入磁盘。binlog是server层，而undo和redo日志都是innodb特有。binlog日志可用于恢复磁盘数据。
8. 写入commit标记到redo日志，主要是用于确保redo日志和binlog日志数据一致。（这里是直接写道日志磁盘文件，而不是redo日志缓存了）
9. 将buffer pool的数据随机写入磁盘，这里才是真正数据入盘。

> 注意：undo日志是直接写入磁盘文件，没有内存缓冲区，而redo存在内存缓冲区。



1. 为什么Mysql不能直接更新磁盘上的数据而且设置这么一套复杂的机制来执行SQL了？ 

因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据性能可能相当差。

因为磁盘随机读写的性能是非常差的，所以直接更新磁盘文件是不能让数据库抗住很高并发的。 Mysql这套机制看起来复杂，但它可以保证每个更新请求都是更新内存BufferPool，然后顺序写日志文件，同时还能 保证各种异常情况下的数据一致性。 

更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是非常高的，要远高于随机读写磁盘文件。

> 如果不引入undo和redo日志体系，那么数据磁盘文件，就得必须来一个请求，都得及时入表，否则，会存在数据丢失风险；但是这样子，经常入表，而且数据磁盘文件没法子确保顺序写入，必然是随机写入，则效率很差。引入undo和redo日志后，则数据可以存放内存缓冲区，定时写入磁盘即可，就算数据丢失也可以利用redo和undo恢复；另外，虽然引入了undo和redo日志，写磁盘，但是由于undo和redo日志是顺序写入，所以效率可以接受。

